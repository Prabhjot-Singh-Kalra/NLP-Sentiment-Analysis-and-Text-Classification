{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74422041",
   "metadata": {},
   "source": [
    "#  Part A: IMDb Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf8607e",
   "metadata": {},
   "source": [
    " The objective of this project is to build a machine learning classification model that\n",
    " can predict the sentiment of IMDb movie reviews. The dataset contains a collection of movie\n",
    " reviews, and each review is labeled as either positive or negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "90c8c553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nltk.download('punkt')\\nnltk.download('stopwords')\\nnltk.download('wordnet')\\nnltk.download('omw-1.4')\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import normalize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#pd.download('')\n",
    "'''nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34456fe5-b505-415e-a120-b2ea144eda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data exploration and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bbe90707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Imdb_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f6689d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "89b2cc79-188c-4c0f-ba2e-85917f528685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "3ba94b5f-b1dc-4271-b511-8e28fceabe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning (removing punctuation and converting to lower case)\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]','',text)# sub method from regular expression module for pattern matching and replacing it with empty string\n",
    "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "46a83aaa-2f3e-4c30-8ed0-53b003e8d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean'] = df['review'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43951298-001d-431d-a2fa-0c4f106f0c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering, model building and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "06719cda-fa0f-4fe4-9486-da04f62f5f41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>one reviewers mentioned watching oz episode yo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "      <td>wonderful little production br br filming tech...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "      <td>thought wonderful way spend time hot summer we...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>basically theres family little boy jake thinks...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "      <td>petter matteis love time money visually stunni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment  \\\n",
       "0  One of the other reviewers has mentioned that ...  positive   \n",
       "1  A wonderful little production. <br /><br />The...  positive   \n",
       "2  I thought this was a wonderful way to spend ti...  positive   \n",
       "3  Basically there's a family where a little boy ...  negative   \n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive   \n",
       "\n",
       "                                               clean  label  \n",
       "0  one reviewers mentioned watching oz episode yo...      1  \n",
       "1  wonderful little production br br filming tech...      1  \n",
       "2  thought wonderful way spend time hot summer we...      1  \n",
       "3  basically theres family little boy jake thinks...      0  \n",
       "4  petter matteis love time money visually stunni...      1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['sentiment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d1c2be-2919-4bc3-b295-96c1312934ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(),LogisticRegression()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(df['clean'],df['label'],test_size=0.2,random_state=42) \n",
    "pipeline.fit(x_train, y_train)\n",
    "pred = pipeline.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d49229b-c6c7-4eed-9624-a937523629b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c92f636-1067-4258-a775-0bd881f37062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:63.75555085641784%\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = make_pipeline(TfidfVectorizer(),SVC()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(df['clean'],df['label'],test_size=0.2,random_state=42) \n",
    "pipeline2.fit(x_train, y_train)\n",
    "pred2 = pipeline2.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred2)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592e7405-927b-4e5a-8e9e-daf05d12d6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "37d88e65-404b-4d05-bc46-af67f54caed1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:45.0%\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = make_pipeline(TfidfVectorizer(),RandomForestClassifier()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(df['clean'],df['sentiment'],test_size=0.2,random_state=42) \n",
    "pipeline3.fit(x_train, y_train)\n",
    "pred3 = pipeline3.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred3)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d00364-0301-4789-ad31-306c476138bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac72667-4816-4af5-bd54-bbed908bfe2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a371b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicting sentiments for new input\n",
    "def predict_sentiment(new_reviews):\n",
    "    preprocessed_rewiews=[\n",
    "        ' '.join([word for word in word_tokenizer(review.lower()) if word.isaplha()\n",
    "                 and word not in stopwords])\n",
    "               for rewiew in new_reviews\n",
    "    ]\n",
    "    rewiews+tfidf = vectorizer.transform(preprocessed_reviews)\n",
    "    predictions = pipeline.predict(reviews+tfidf)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9540b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Please enter your review')\n",
    "while True:\n",
    "    user_input=input('Enter review -')\n",
    "    if user_inpur.lower()=='exit':\n",
    "        break\n",
    "    predicted_sentiment= predict_sentiment([user_input])\n",
    "    #display predictions\n",
    "    print(f'Review:{user_input}\\n Prediction sentient:\n",
    "          {predicted_sentiment[0]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a27a5ce-c8b5-4abe-a132-d7a8278c210e",
   "metadata": {},
   "source": [
    "# final report  \n",
    "in this we were given a csv file in  containing reviews from the IMDb dataset and need to \n",
    "predict the sentiment (positive or negative) based on the text of the reviews.\n",
    "we hve used nltk library for performing classification tasks\n",
    "steps:\n",
    "- loaded the data using pandas function\n",
    "- performed ELT and preprocessing\n",
    "- tokenised, lemmatized the data\n",
    "- used encoding to assign labels to sentiment column\n",
    "- used logistic regression, support vector machine and random forest for model creation\n",
    "- used evlauation matrices for analysing the performance\n",
    "  \n",
    "Key takeaways:\n",
    "\n",
    "SVM is giving the best result as compared to logistic regression and random forest .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb4c222",
   "metadata": {},
   "source": [
    "# Part B: News Article Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0c12db",
   "metadata": {},
   "source": [
    "The objective of this project is to build a classification model that can automatically\n",
    " categorize news articles into different predefined categories. The model will be trained using\n",
    " a labeled dataset of news articles and will output the most likely category (e.g., sports,\n",
    " politics, or technology) for any given article "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e46f53-9bca-4f78-aa51-b961e0735e74",
   "metadata": {},
   "source": [
    "### 1. Data Collection and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2754bdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>links</th>\n",
       "      <th>short_description</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>143 Miles in 35 Days: Lessons Learned</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-l...</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "      <td>running-lessons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Talking to Yourself: Crazy or Crazy Helpful?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/talking-t...</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "      <td>talking-to-yourself-crazy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Crenezumab: Trial Will Gauge Whether Alzheimer...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/crenezuma...</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "      <td>crenezumab-alzheimers-disease-drug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Oh, What a Difference She Made</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/meaningfu...</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "      <td>meaningful-life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Green Superfoods</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/green-sup...</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "      <td>green-superfoods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           headline  \\\n",
       "0  WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
       "1  WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
       "2  WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
       "3  WELLNESS                     Oh, What a Difference She Made   \n",
       "4  WELLNESS                                   Green Superfoods   \n",
       "\n",
       "                                               links  \\\n",
       "0  https://www.huffingtonpost.com/entry/running-l...   \n",
       "1  https://www.huffingtonpost.com/entry/talking-t...   \n",
       "2  https://www.huffingtonpost.com/entry/crenezuma...   \n",
       "3  https://www.huffingtonpost.com/entry/meaningfu...   \n",
       "4  https://www.huffingtonpost.com/entry/green-sup...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Resting is part of training. I've confirmed wh...   \n",
       "1  Think of talking to yourself as a tool to coac...   \n",
       "2  The clock is ticking for the United States to ...   \n",
       "3  If you want to be busy, keep trying to be perf...   \n",
       "4  First, the bad news: Soda bread, corned beef a...   \n",
       "\n",
       "                             keywords  \n",
       "0                     running-lessons  \n",
       "1           talking-to-yourself-crazy  \n",
       "2  crenezumab-alzheimers-disease-drug  \n",
       "3                     meaningful-life  \n",
       "4                    green-superfoods  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data_news.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0a9f783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   category           50000 non-null  object\n",
      " 1   headline           50000 non-null  object\n",
      " 2   links              50000 non-null  object\n",
      " 3   short_description  49994 non-null  object\n",
      " 4   keywords           47294 non-null  object\n",
      "dtypes: object(5)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "231b1e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data =data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9d05a54d-449f-404e-953a-e305eb55dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text cleaning (removing punctuation and converting to lower case)\n",
    "def preprocess_text(text):\n",
    "    text_ = text.lower()\n",
    "    text_ = re.sub(r'[^a-z\\s]','',text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5180fba4-3622-431c-99ec-1c77bd4c3c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_text'] = data['short_description'].astype(str).apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "db2acd36-352c-4a2a-83a9-2b8600b93a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>links</th>\n",
       "      <th>short_description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>143 Miles in 35 Days: Lessons Learned</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-l...</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "      <td>running-lessons</td>\n",
       "      <td>Resting part training . I 've confirmed I sort...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Talking to Yourself: Crazy or Crazy Helpful?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/talking-t...</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "      <td>talking-to-yourself-crazy</td>\n",
       "      <td>Think talking tool coach challenge , narrate e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Crenezumab: Trial Will Gauge Whether Alzheimer...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/crenezuma...</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "      <td>crenezumab-alzheimers-disease-drug</td>\n",
       "      <td>The clock ticking United States find cure . Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Oh, What a Difference She Made</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/meaningfu...</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "      <td>meaningful-life</td>\n",
       "      <td>If want busy , keep trying perfect . If want h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Green Superfoods</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/green-sup...</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "      <td>green-superfoods</td>\n",
       "      <td>First , bad news : Soda bread , corned beef be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           headline  \\\n",
       "0  WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
       "1  WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
       "2  WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
       "3  WELLNESS                     Oh, What a Difference She Made   \n",
       "4  WELLNESS                                   Green Superfoods   \n",
       "\n",
       "                                               links  \\\n",
       "0  https://www.huffingtonpost.com/entry/running-l...   \n",
       "1  https://www.huffingtonpost.com/entry/talking-t...   \n",
       "2  https://www.huffingtonpost.com/entry/crenezuma...   \n",
       "3  https://www.huffingtonpost.com/entry/meaningfu...   \n",
       "4  https://www.huffingtonpost.com/entry/green-sup...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Resting is part of training. I've confirmed wh...   \n",
       "1  Think of talking to yourself as a tool to coac...   \n",
       "2  The clock is ticking for the United States to ...   \n",
       "3  If you want to be busy, keep trying to be perf...   \n",
       "4  First, the bad news: Soda bread, corned beef a...   \n",
       "\n",
       "                             keywords  \\\n",
       "0                     running-lessons   \n",
       "1           talking-to-yourself-crazy   \n",
       "2  crenezumab-alzheimers-disease-drug   \n",
       "3                     meaningful-life   \n",
       "4                    green-superfoods   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  Resting part training . I 've confirmed I sort...  \n",
       "1  Think talking tool coach challenge , narrate e...  \n",
       "2  The clock ticking United States find cure . Th...  \n",
       "3  If want busy , keep trying perfect . If want h...  \n",
       "4  First , bad news : Soda bread , corned beef be...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "71dbc726-215d-49b0-8975-60393b3a2996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>headline</th>\n",
       "      <th>links</th>\n",
       "      <th>short_description</th>\n",
       "      <th>keywords</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>143 Miles in 35 Days: Lessons Learned</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/running-l...</td>\n",
       "      <td>Resting is part of training. I've confirmed wh...</td>\n",
       "      <td>running-lessons</td>\n",
       "      <td>Resting part training . I 've confirmed I sort...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Talking to Yourself: Crazy or Crazy Helpful?</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/talking-t...</td>\n",
       "      <td>Think of talking to yourself as a tool to coac...</td>\n",
       "      <td>talking-to-yourself-crazy</td>\n",
       "      <td>Think talking tool coach challenge , narrate e...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Crenezumab: Trial Will Gauge Whether Alzheimer...</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/crenezuma...</td>\n",
       "      <td>The clock is ticking for the United States to ...</td>\n",
       "      <td>crenezumab-alzheimers-disease-drug</td>\n",
       "      <td>The clock ticking United States find cure . Th...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Oh, What a Difference She Made</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/meaningfu...</td>\n",
       "      <td>If you want to be busy, keep trying to be perf...</td>\n",
       "      <td>meaningful-life</td>\n",
       "      <td>If want busy , keep trying perfect . If want h...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WELLNESS</td>\n",
       "      <td>Green Superfoods</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/green-sup...</td>\n",
       "      <td>First, the bad news: Soda bread, corned beef a...</td>\n",
       "      <td>green-superfoods</td>\n",
       "      <td>First , bad news : Soda bread , corned beef be...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                           headline  \\\n",
       "0  WELLNESS              143 Miles in 35 Days: Lessons Learned   \n",
       "1  WELLNESS       Talking to Yourself: Crazy or Crazy Helpful?   \n",
       "2  WELLNESS  Crenezumab: Trial Will Gauge Whether Alzheimer...   \n",
       "3  WELLNESS                     Oh, What a Difference She Made   \n",
       "4  WELLNESS                                   Green Superfoods   \n",
       "\n",
       "                                               links  \\\n",
       "0  https://www.huffingtonpost.com/entry/running-l...   \n",
       "1  https://www.huffingtonpost.com/entry/talking-t...   \n",
       "2  https://www.huffingtonpost.com/entry/crenezuma...   \n",
       "3  https://www.huffingtonpost.com/entry/meaningfu...   \n",
       "4  https://www.huffingtonpost.com/entry/green-sup...   \n",
       "\n",
       "                                   short_description  \\\n",
       "0  Resting is part of training. I've confirmed wh...   \n",
       "1  Think of talking to yourself as a tool to coac...   \n",
       "2  The clock is ticking for the United States to ...   \n",
       "3  If you want to be busy, keep trying to be perf...   \n",
       "4  First, the bad news: Soda bread, corned beef a...   \n",
       "\n",
       "                             keywords  \\\n",
       "0                     running-lessons   \n",
       "1           talking-to-yourself-crazy   \n",
       "2  crenezumab-alzheimers-disease-drug   \n",
       "3                     meaningful-life   \n",
       "4                    green-superfoods   \n",
       "\n",
       "                                        cleaned_text  label  \n",
       "0  Resting part training . I 've confirmed I sort...      8  \n",
       "1  Think talking tool coach challenge , narrate e...      8  \n",
       "2  The clock ticking United States find cure . Th...      8  \n",
       "3  If want busy , keep trying perfect . If want h...      8  \n",
       "4  First , bad news : Soda bread , corned beef be...      8  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['category'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6dd89cf-5512-4075-b4e0-69741582a0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "2    4858\n",
       "7    4856\n",
       "1    4854\n",
       "9    4844\n",
       "5    4759\n",
       "8    4736\n",
       "4    4708\n",
       "6    4704\n",
       "0    4508\n",
       "3    4461\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab00d3d5-8d52-47bf-b3d5-6427fcb7e4fb",
   "metadata": {},
   "source": [
    "### Feature Extraction and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "cdfea220-7f87-434c-9f18-523f506b28ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fc4cfab6-8015-428d-a87c-054824b3a80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:67.92133643476423%\n"
     ]
    }
   ],
   "source": [
    "pipeline = make_pipeline(TfidfVectorizer(),LogisticRegression()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(data['cleaned_text'],data['label'],test_size=0.2,random_state=42) \n",
    "pipeline.fit(x_train, y_train)\n",
    "pred = pipeline.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8f42e8-6569-4bdc-a85a-bbbd04f7bc1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9e90a401-e4a3-44f0-99ed-1f6f2b87bcce",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.66      0.68       879\n",
      "           1       0.57      0.62      0.59       932\n",
      "           2       0.72      0.73      0.73      1025\n",
      "           3       0.65      0.63      0.64       865\n",
      "           4       0.65      0.58      0.61       950\n",
      "           5       0.72      0.80      0.76       925\n",
      "           6       0.78      0.68      0.73       985\n",
      "           7       0.70      0.69      0.70       961\n",
      "           8       0.62      0.69      0.66       967\n",
      "           9       0.69      0.69      0.69       969\n",
      "\n",
      "    accuracy                           0.68      9458\n",
      "   macro avg       0.68      0.68      0.68      9458\n",
      "weighted avg       0.68      0.68      0.68      9458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f60fc-da16-4d73-a018-9515a39871c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60ca15c6-9b73-4f9f-a319-3b4da3724914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:69.70818354831889%\n"
     ]
    }
   ],
   "source": [
    "pipeline2 = make_pipeline(TfidfVectorizer(),SVC()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(data['cleaned_text'],data['label'],test_size=0.2,random_state=42) \n",
    "pipeline2.fit(x_train, y_train)\n",
    "pred = pipeline2.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e156850-8a5e-4f53-a8da-6cc79855493e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.74      0.77       879\n",
      "           1       0.51      0.69      0.59       932\n",
      "           2       0.71      0.74      0.73      1025\n",
      "           3       0.68      0.63      0.66       865\n",
      "           4       0.65      0.59      0.62       950\n",
      "           5       0.85      0.83      0.84       925\n",
      "           6       0.83      0.67      0.74       985\n",
      "           7       0.70      0.67      0.68       961\n",
      "           8       0.64      0.70      0.67       967\n",
      "           9       0.71      0.70      0.70       969\n",
      "\n",
      "    accuracy                           0.70      9458\n",
      "   macro avg       0.71      0.70      0.70      9458\n",
      "weighted avg       0.71      0.70      0.70      9458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37c110d-6150-439b-a3df-1a63bcd2409d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b42e9cfa-0c40-469a-926c-68f723becf0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:63.75555085641784%\n"
     ]
    }
   ],
   "source": [
    "pipeline3 = make_pipeline(TfidfVectorizer(),RandomForestClassifier()) \n",
    "x_train,x_test,y_train,y_test = train_test_split(data['cleaned_text'],data['label'],test_size=0.2,random_state=42) \n",
    "pipeline3.fit(x_train, y_train)\n",
    "pred = pipeline3.predict(x_test)\n",
    "print(f'accuracy:{accuracy_score(y_test,pred)*100}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b1ea386-556d-4cb6-b43a-8d0343b62de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.76      0.77       879\n",
      "           1       0.42      0.62      0.50       932\n",
      "           2       0.60      0.73      0.66      1025\n",
      "           3       0.68      0.59      0.63       865\n",
      "           4       0.64      0.49      0.56       950\n",
      "           5       0.74      0.85      0.79       925\n",
      "           6       0.73      0.59      0.65       985\n",
      "           7       0.69      0.56      0.62       961\n",
      "           8       0.62      0.57      0.60       967\n",
      "           9       0.62      0.62      0.62       969\n",
      "\n",
      "    accuracy                           0.64      9458\n",
      "   macro avg       0.65      0.64      0.64      9458\n",
      "weighted avg       0.65      0.64      0.64      9458\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6499062-f029-422c-8890-4357afcaa679",
   "metadata": {},
   "source": [
    "# final report  \n",
    "in this we were given a excel file containing news articles, we need to classify news articles\n",
    "into predefined categories, such as sports, politics, and technology, based on their content.\n",
    "we hve used nltk library for performing classification tasks\n",
    "steps:\n",
    "- loaded the data using pandas function\n",
    "- performed ELT and preprocessing\n",
    "- tokenised, lemmatized the data\n",
    "- used encoding to assign labels to category column\n",
    "- used logistic regression, support vector machine and random forest for model creation\n",
    "- used evlauation matrices for analysing the performance\n",
    " \n",
    "Key takeaways:\n",
    "\n",
    "SVM is giving the best result.\n",
    "\n",
    "the accuracy of model is approx. 70%  with decent recall and f1 score values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a57e02-1f39-41ec-84b2-beb2d8bdbebf",
   "metadata": {},
   "source": [
    "## video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01f9cc6-09a6-4d92-951b-ff37fc017728",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://drive.google.com/file/d/1-q7bQ6zer_zPGhvbhiB20xANUW0XrOYq/view?usp=drivesdk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
